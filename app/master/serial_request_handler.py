import json
import os
import uuid

from app.master.atom_grouper import AtomGrouper
from app.master.atomizer import AtomizerError
from app.master.build_request import BuildRequest
from app.master.subjob import Subjob
from app.master.time_based_atom_grouper import TimeBasedAtomGrouper
from app.util.conf.configuration import Configuration
from app.util.log import get_logger
from app.util import util


class SerialRequestHandler(object):

    def __init__(self):
        self._logger = get_logger(__name__)

    def handle_request(self, build):
        """
        Prepare a Build to be distributed across slaves.

        # Fetch the repo/container/execute commands
        # Get the cluster_runner.yaml file
        # Pull all of the atoms by running the atomizer
        # Group the atoms into groupings
        # Generate subjobs
        # Prepare the build

        :param build: the Build instance to be prepared to be distributed across slaves
        :type build: Build
        """
        build_id = build.build_id()
        build_request = build.build_request
        if not isinstance(build_request, BuildRequest):
            raise RuntimeError('Build {} has no associated request object.'.format(build_id))

        # Generate a unique project build directory name that will be symlinked to the actual project directory
        # later on when the project gets fetched.
        build_specific_project_directory = self._generate_unique_symlink_path_for_build_repo()

        # Because build_specific_project_directory is entirely internal and generated by ClusterRunner (it is a
        # build-unique generated symlink), we must manually add it to the project_type_params
        # @TODO: directly passing around the user-specified project_type_params may no longer be the right approach as
        # @TODO: we get more and more internal clusterrunner-specific arguments such as build_project_directory
        # todo(joey): we should move/refactor the concurrency protection in build.prepare() to also protect this path
        project_type_params = build_request.build_parameters()
        project_type_params.update({'build_project_directory': build_specific_project_directory})
        project_type = util.create_project_type(project_type_params)

        if project_type is None:
            raise BuildProjectError('Build failed due to an invalid build type.')

        self._logger.info('Fetching project for build {}.', build_id)
        project_type.setup_build()

        self._logger.info('Successfully fetched project for build {}.', build_id)
        job_config = project_type.job_config()

        if job_config is None:
            # @TODO: need to be able to dump applicable information from project_type for helpful error message
            build.mark_failed('Build failed while trying to parse cluster_runner.yaml.')
            return

        subjobs = self._compute_subjobs_for_build(build_id, job_config, project_type)
        build.prepare(subjobs, project_type, job_config)

    def _compute_subjobs_for_build(self, build_id, job_config, project_type):
        """

        :type build_id: int
        :type job_config: JobConfig
        :param project_type: the docker, directory, or git repo project_type that this build is running in
        :type project_type: project_type.project_type.ProjectType
        :rtype: list[Subjob]
        """
        try:
            atoms_list = job_config.atomizer.atomize_in_project(project_type)
        except AtomizerError as ex:
            raise BuildProjectError('Build failed during atomization.') from ex

        # Group the atoms together using some grouping strategy
        timing_file_path = project_type.timing_file_path(job_config.name)
        grouped_atoms = self._grouped_atoms(
            atoms_list,
            job_config.max_executors,
            timing_file_path,
            project_type.project_directory
        )

        # Generate subjobs for each group of atoms
        subjobs = []
        for subjob_id in range(len(grouped_atoms)):
            atoms = grouped_atoms[subjob_id]
            subjobs.append(Subjob(build_id, subjob_id, project_type, job_config, atoms))
        return subjobs

    def _grouped_atoms(self, atoms, max_executors, timing_file_path, project_directory):
        """
        Return atoms that are grouped for optimal CI performance.

        If a timing file exists, then use the TimeBasedAtomGrouper.
        If not, use the default AtomGrouper (groups each atom into its own subjob).

        :param atoms: all of the atoms to be run this time
        :type atoms: list[str]
        :param max_executors: the maximum number of executors for this build
        :type max_executors: int
        :param timing_file_path: path to where the timing data file would be stored (if it exists) for this job
        :type timing_file_path: str
        :type project_directory: str
        :return: the grouped atoms (in the form of list of lists of strings)
        :rtype: list[list[str]]
        """
        atom_time_map = None

        if os.path.isfile(timing_file_path):
            with open(timing_file_path, 'r') as json_file:
                try:
                    atom_time_map = json.load(json_file)
                except ValueError:
                    self._logger.warning('Failed to load timing data from file that exists {}', timing_file_path)
                    pass

        if atom_time_map is not None and len(atom_time_map) > 0:
            atom_grouper = TimeBasedAtomGrouper(atoms, max_executors, atom_time_map, project_directory)
        else:
            atom_grouper = AtomGrouper(atoms, max_executors)

        return atom_grouper.groupings()

    def _generate_unique_symlink_path_for_build_repo(self):
        """
        Generate a unique symlink path for a build-specific repo. This method does NOT generate the symlink itself.

        :rtype: str
        """
        return os.path.join(Configuration['build_symlink_directory'], str(uuid.uuid4()))


class BuildProjectError(Exception):
    """
    The build project could not be created or fetched
    """
